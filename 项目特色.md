UER-py有如下几方面优势:
- __可复现__ UER-py已在许多数据集上进行了测试，与原始预训练模型实现（例如BERT，GPT，ELMo，T5）的表现相匹配。
- __多GPU模式__ UER-py支持CPU、单机单GPU、单机多GPU、多机多GPU训练模式。BERT类模型计算量大。多GPU模式使得UER-py能够在大规模语料上进行预训练
- __模块化__ UER-py使用解耦的模块化设计框架。模型分成Embedding、Encoder、Target三个部分。每个部分提供清晰的接口，便于对模型的模块进行组合优化
- __高效__ UER-py优化了预处理，预训练和微调阶段的代码，从而大大提高了速度并减少了内存需求
- __模型仓库__ 我们维护并持续发布中文预训练模型。用户可以根据具体任务的要求，从中选择合适的预训练模型使用。
- __SOTA结果__ UER-py支持全面的下游任务，包括文本分类、文本对分类、序列标注、阅读理解等
- __相关功能__ UER-py提供了丰富的预训练相关的功能和优化，包括特征抽取、近义词检索、预训练模型转换、模型集成、混合精度训练等